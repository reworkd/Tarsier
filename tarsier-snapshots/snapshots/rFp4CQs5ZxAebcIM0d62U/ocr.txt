-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[@1] Hacker News [@2] new [@3] past [@4] comments [@5] ask [@6] show [@7] jobs [@8] submit                                                                                                                       [@9] login
                          [@11] Learnings from fine-tuning LLM on my Telegram messages
                          [@12] asmirnov.xyz
                          [14] 150 points [13] by furiousteabag 10 hours ago hide   past   favorite 43 comments






                           [@24] jstrieb [@25] 1 hour ago [@26] next [@27] [–]
                           [28] This post and its findings are really interesting!
                           [29] Back when the I forced a bot to watch 1000 hours..." memes were popular ( https://knowyourmeme.com/memes/i-forced-a-bot [30] ), ages ago in AI/ML time, I
                           tried to do something similar by fine-tuning GPT-2 on messages from a group chat of my friends. Since there were years of chat data, it seemed like a really good
                           opportunity to test whether the language model would capture everyone's personality and generate funny, uncanny-valley versions of our banter.
                           [32] Turns out that the group chat was used nearly exclusively for sending funny pictures and videos (that the language model obviously couldn't see), and for making
                           plans to meet up. The generated conversations almost exclusively consisted of a random group chat member starting with there is a party tonight, who wants to go? and
                           others saying I'm down" or when? or where? It was 0                         banter, and 100        logistics.
                           [33] It was pretty hilarious in its own way, but not for the reasons anyone expected! I didn't learn very much about language models with that experiment, but I did learn
                           that my friends' group chat is actually pretty boring.
                           [34] I guess the best banter happens in real life. Glad to see it worked out somewhat more interestingly for this person, even if they did allude to some similar results in
                           their closing thoughts section.
                           reply
                           [@37] thefourthchime [@38] 8 hours ago [@39] prev [@40] next [@41] [–]
                           [42] This part caught my eye:
                           [43] Using a half-precision FSDP full shard with a 1024 sequence length and a micro batch size of 2 required 63GB of VRAM on each of the eight A100 80 GB GPUs. The
                           training, lasting three epochs, took just 20 minutes. The total cost for the VM was 8.88 per hour, resulting in                             3, not including the time for experiments and bug fixes."
                           [44] I wondered where you could rent cycles on a machine like that, a quick Google found that p4d.24xlarge on AWS is available, while the on-demand cost is                                              20.1755
                           per hour, the Spot is only 8.99 (I guess it's gone up? )
                           [45] Cool to know I could fine-tune for only               3.
                           reply
                                   [@48] furiousteabag [@49] 8 hours ago [@50] parent [@51] next [@52] [–]
                                   [53] I've been using vast.ai for a very long time. It is like a GPU marketplace, where people rent and lease GPUs. There are a lot of VMs with 4090, and beasts like
                                   8xA100 80GB are also available from time to time.
                                   [@54] reply
                                           [@56] skerit [@57] 6 hours ago [@58] root [@59] parent [@60] next [@61] [–]
                                           [62] I've used vast.ai to do some fine-tuning just a few days ago. It is indeed pretty great, though some servers fail to start up properly, or have some weird
                                           performance issues. I also wish they had more templates to try.
                                           [@63] reply
                                                   [@65] icelancer [@66] 2 hours ago [@67] root [@68] parent [@69] next [@70] [–]
                                                   [71] Yeah it works pretty well for the price - just need to be comfortable with running code and putting data on random peoples' computers (which I
                                                   am for certain things). Someone on HN posted a script or snippet of output on mass-testing vast.ai servers for connectivity and configuration, and
                                                   auto-labeling them using their API. Wish I could find it now... maybe with the search?
                                                   [@72] reply
                                   [@74] jsight [@75] 5 hours ago [@76] parent [@77] prev [@78] next [@79] [–]
                                   [80] I think Tensordock and vast.ai are cheaper than AWS. Lambda labs can be as well, but they seem to only have reserved instances now.
                                   [@81] reply
                                           [@83] cosmojg [@84] 4 hours ago [@85] root [@86] parent [@87] next [@88] [–]
                                           [89] runpod.io is another good-and-cheap option
                                           [@90] reply
                                   [@92] bllchmbrs [@93] 2 hours ago [@94] parent [@95] prev [@96] next [@97] [–]
                                   [98] Check out other prices on https://gpumonger.com/
                                   [100] Disclosure: I collected the data and built the site, but it has a ton of comparison data for GPU clouds.
                                   reply
                                   [@103] siquick [@104] 5 hours ago [@105] parent [@106] prev [@107] next [@108] [–]
                                   [109] Excuse the ignorance but are you using these instances to fine tune a fresh install of a model, and then when you ve finished fine tuning it do you download
                                   the whole model from the instance for use somewhere else?
                                   [@110] reply
                           [@112] gwern [@113] 5 hours ago [@114] prev [@115] next [@116] [–]
                           [117] My data collator ensures that the loss is only calculated based on someone s response. Predicting who will speak next is relatively straightforward, and we don t
                           want the model to focus on learning that. Therefore, parts of the conversation where the loss is calculated are highlighted in bold.
                           [118] If it's so easy, then you don't need to remove it. The model will solve it easily and focus on everything else. At best, you save some parameters and compute, at
                           worst, you are damaging its ability to learn important things like conversational skills or modeling people. When it comes to LLMs, more is more, and trying to
                           hand-engineer the dataset or think [120] for [119] the LLM can backfire in very subtle and difficult to diagnose ways.
                           [121]     Ok, it is capable of forming coherent sentences. The most noticeable problem is its lack of awareness regarding the context of the conversations which leads to
                           bland and generic replies. The messages lacked any distinct style, feeling quite basic...                          Conversations have become more interesting and engaging, although there s
                           still a risk of losing context. Russian language performance has improved, but errors still occur. I believe that before fine-tuning for a specific task with limited data, like
                           mine, it would be beneficial to first fine-tune the model unsupervised on a large corpus of Russian texts. Additionally, incorporating common conversation partners names
                           as separate tokens might enhance the quality. I wouldn t say it has turned out to be significantly better than LoRA. It might be more effective to focus solely on a single
                           person and calculate the loss based only on my responses (or someone else s), instead of trying to learn about each and every conversational partner.
                           reply
                           [@124] goda90 [@125] 8 hours ago [@126] prev [@127] next [@128] [–]
                           [129] We're probably quite some time off from the bio-mimetic android part, but we're feeling closer and closer to the AI replacement avatar from the Black Mirror episode
                            Be Right Back"[0]
                           [130] [0] https://en.wikipedia.org/wiki/Be_Right_Back
                           reply
                           [@134] NoraCodes [@135] 9 hours ago [@136] prev [@137] next [@138] [–]
                           [139] A meta-comment, but, what is the difference between learnings" and lessons"? Why use the former when we have the latter?
                           [@140] reply
                                   [@142] furyofantares [@143] 8 hours ago [@144] parent [@145] next [@146] [–]
                                   [147] Learnings implies a report of your own experience; lessons implies something prepared as teaching material for the audience. (In the context of the title
                                   sentence anyway.)
                                   [@148] reply
                                           [@150] xanderlewis [@151] 7 hours ago [@152] root [@153] parent [@154] next [@155] [–]
                                           [156] Lessons to me also seems to carry a sense of regret, as in things (we) got wrong. Learnings is a more obscure word that I would take to mean
                                           something more neutral: literally things (I ve) learnt.
                                           [@157] reply
                                           [@159] kagol [@160] 5 hours ago [@161] root [@162] parent [@163] prev [@164] next [@165] [–]
                                           [166] Perhaps findings" over learnings", based on your description?
                                           [@167] reply
                                   [@169] amccollum [@170] 6 hours ago [@171] parent [@172] prev [@173] next [@174] [–]
                                   [175] This usage of learnings", while certainly more common in business jargon" today, was used by Shakespeare:
                                   https://www.opensourceshakespeare.org/views/plays/play_view....
                                   reply
                                           [@179] nescioquid [@180] 4 hours ago [@181] root [@182] parent [@183] next [@184] [–]
                                           [185] Some words in Shakespeare have different meanings today or have simply left standard usage. I don't think the presence of a word in Shakespeare
                                           means it is de facto good style to use today.
                                           [186] From a correctness stand-point, I think a descriptionist would be satisfied with an attested usage, especially from such a source. From a style point of
                                           view, I still find myself feeling embarrassed for the author when I encounter this usage (which is my own problem).
                                           reply
                                   [@189] swatcoder [@190] 8 hours ago [@191] parent [@192] prev [@193] next [@194] [–]
                                   [@195] https://en.m.wiktionary.org/wiki/learnings
                                   [196] Beyond what's noted there (contemporary business jargon), English is diffused across the globe and has many regional variations that are different than
                                   class-signalling/formal American and British usage. As we all encounter each other online, it's not always worth over-analyzing word choice when you can
                                   understand the intent.
                                   [@197] reply
                                   [@199] bee_rider [@200] 8 hours ago [@201] parent [@202] prev [@203] next [@204] [–]
                                   [205] I think when you ask what the difference between two phrases is, people will really dig down to try and find a difference.
                                   [206] IMO in this context it is basically shorthand for things I learned/lessons learned while tuning LLM,                             and either would be fine. It is sort of an informal list of
                                   stuff the author learned.
                                   [207] In my experience (nothing special, just another native speaker) lessons from event                               is the more typical American (at least) English phrase. But it is sort
                                   of close to Lessons on.          Lessons on would imply more refined material that is more narrowly focused on teaching. So I wonder if the author decided they just
                                   didn t want to worry about any confusion, or the possibility that they might misuse a phrase.
                                   reply
                                   [@210] klooney [@211] 8 hours ago [@212] parent [@213] prev [@214] next [@215] [–]
                                   [216] I've always associated it with Indian English, possibly it's a dialect thing that's spread from that community.
                                   [@217] reply
                                           [@219] xanderlewis [@220] 7 hours ago [@221] root [@222] parent [@223] next [@224] [–]
                                           [225] Maybe it s Kazakh. https://en.m.wikipedia.org/wiki/Borat
                                            -)
                                           reply
                                   [@229] c0pium [@230] 8 hours ago [@231] parent [@232] prev [@233] next [@234] [–]
                                   [235] Gotta earn those fat management consultant fees somehow. I m sure there s a whole team at McKinsey doing nothing but inventing new ways to say the
                                   same things.
                                   [@236] reply
                                           [@238] fl7305 [@239] 7 hours ago [@240] root [@241] parent [@242] next [@243] [–]
                                           [244] In Swedish, there's a commonly used word l                  rdomar" which is a direct match for learnings".
                                           [245] But where the Swedish word sounds natural in that language, learnings" just sounds wrong in English, even though it apparently is technically correct.
                                           reply
                                   [@248] Jolter [@249] 8 hours ago [@250] parent [@251] prev [@252] next [@253] [–]
                                   [254] Lessons may be given, but are not necessarily learned.
                                   [@255] reply
                                   [@257] bigdict [@258] 9 hours ago [@259] parent [@260] prev [@261] next [@262] [–]
                                   [263] learnings        lessons learned
                                   [@264] reply
                                   [@266] AlexCoventry [@267] 7 hours ago [@268] parent [@269] prev [@270] next [@271] [–]
                                   [272] I think it's new. I've only heard it in the last few years.
                                   [@273] reply
                                   [@275] catlover76 [@276] 6 hours ago [@277] parent [@278] prev [@279] next [@280] [–]
                                   [281] I assumed the author was a non-native English speaker
                                   [@282] reply
                           [@284] spdif899 [@285] 2 hours ago [@286] prev [@287] next [@288] [–]
                           [289] Really interesting - as another person who's used telegram for several long-standing group chats, I imagine a tool to simplify this would be well-received.
                           [290] I've wondered since fine-tuning started being a thing how long it'd be before somebody makes a utility where you can dump a giant chat export into it and an API
                           key and then it fine tunes a Telegram bot that can imitate any of your friends - would be fun to play with and even create a group chat with multiple friend-bots talking to
                           each other to see how long until it goes off the rails.
                           reply
                           [@293] u385639 [@294] 8 hours ago [@295] prev [@296] next [@297] [–]
                           [298] Great post. I wonder how much this can improve if you RAG-ify a diverse set of contextual data, for example calendar, meals, recent conversations from the real
                           world, etc.
                           [299] It's also interesting that            was translated to 'damn'. :)
                           reply
                                   [@302] furiousteabag [@303] 7 hours ago [@304] parent [@305] next [@306] [–]
                                   [307] I think incorporating knowledge from other apps is a good next step because the model definitely lacks the context of what is going on right now. The nature
                                   of instant messaging is that most of the messages are about what is happening right now or what will happen in the near future, so past communication history
                                   does not help much.
                                   [@308] reply
                           [@310] haltist [@311] 8 hours ago [@312] prev [@313] next [@314] [–]
                           [315] Great example of immortal digital avatars. This is just a simple personal avatar but it is possible to make technological gods with the same techniques. All that's
                           needed is scale and 80B.
                           [@316] reply
                           [@318] lloydatkinson [@319] 7 hours ago [@320] prev [@321] next [@322] [–]
                           [323] Learnings is such a horrible word
                           [@324] reply
                           [@326] 123sereusername [@327] 7 hours ago [@328] prev [@329] [–]
                           [330] Learnings" While it might be legal, Learnings is a terrible abuse of the English language.
                           [@331] reply
                                   [@333] sfink [@334] 6 hours ago [@335] parent [@336] next [@337] [–]
                                   [338] I'm a native English speaker from the US, and a pedant who hates ask" as a noun, workshop" as a verb, and performant" as a word. But I don't get the
                                   hate for learnings" here. What's wrong with it?               Lessons" connotes negativity, stuff I learned" doesn't naturally fit into many sentences, and useful information
                                   gleaned" can be shoved right back up the tightly puckered ass it came out of.
                                   [339] What's the problem? That title is exactly the way I would have written it.
                                   reply
                                           [@342] korhojoa [@343] 5 hours ago [@344] root [@345] parent [@346] next [@347] [–]
                                           [348] Out of curiosity, what's your take on how to write this item requires repair"?
                                           [349] It needs repaired" is something I've seen, which to me is confusing, because it seems like to be" is missing. When did needs" run away from the
                                           words it's been associated with before?
                                           reply
                                                   [@352] pweezy [@353] 4 hours ago [@354] root [@355] parent [@356] next [@357] [–]
                                                   [358] This is a regionalism in parts of the US, which I ve seen described as Pittsburgh and its surroundings.
                                                   [359] I come across it often and struggle with cognitive dissonance every time - I know of the regionalism but it feels so strongly like a glaring
                                                   grammatical error.
                                                   [360] I see/hear the specific phrase needs fixed most often.
                                                   reply
                                                   [@363] swatcoder [@364] 5 hours ago [@365] root [@366] parent [@367] prev [@368] next [@369] [–]
                                                   [370] They wrote this for you, I think:
                                                   https://ygdp.yale.edu/phenomena/needs-washed
                                                   reply
                                                   [@374] esafak [@375] 5 hours ago [@376] root [@377] parent [@378] prev [@379] next [@380] [–]
                                                   [381] So you're saying needs" is not doing the needful.
                                                   [@382] reply
                                                   [@384] sfink [@385] 4 hours ago [@386] root [@387] parent [@388] prev [@389] next [@390] [–]
                                                   [391] This shit's broke."
                                                   [392] Seriously, though, I'm with you on It needs to be repaired."
                                                   [393] Then again, I went to school in the land of the yinzers, so it needs repaired" doesn't even sound all that off to me anymore even though I'd
                                                   never use it myself. (I kind of mentally map it to it needs repairing". ) But I think of that as a dialect of English, with no bearing on standard" English.
                                                   [394] For standard English, it has to be it needs to be repaired", it requires repair", it needs repairing", or excuse me, my good sir, but I do believe
                                                   that this shit here is most definitely in need of repair".
                                                   reply
                                           [@397] kagol [@398] 5 hours ago [@399] root [@400] parent [@401] prev [@402] next [@403] [–]
                                           [404] I always thought of learning" as an uncountable noun.
                                           [@405] reply
                                   [@407] ryanklee [@408] 7 hours ago [@409] parent [@410] prev [@411] next [@412] [–]
                                   [413] This is a ridiculous, arbitrary judgment that has nothing to do with anything even remotely related to this post. This type of pedantry is low-brow and
                                   annoying.
                                   [@414] reply
                                           [@416] aerhardt [@417] 5 hours ago [@418] root [@419] parent [@420] next [@421] [–]
                                           [422] It's also plainly wrong, because learnings" is perfectly commonplace.
                                           [@423] reply
                                   [@425] amccollum [@426] 6 hours ago [@427] parent [@428] prev [@429] [–]
                                   [430] Take it up with Shakespeare?
                                   https://www.opensourceshakespeare.org/views/plays/play_view....
                                   reply

                                                                                             [@433] Guidelines [@434] FAQ [@435] Lists [@436] API [@437] Security [@438] Legal [@439] Apply to YC [@440] Contact
                                                                                                          [441] Search:
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Token count: 4653