---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
**[0] Rohan Pandey**
                                                                                                                **[1] AI Researcher &**
                                                                                                                **[2] 10x Hackathon Winner**



                                                                                                                        [$11] Email me
                                                                                                                    [$12] Schedule chat

                          [13] I'm an Artificial Intelligence researcher who recently graduated with CS honors from [16] Carnegie Mellon [14]. I've won [17] 10+
                          hackathons [15] and published several papers at [18] ML conferences.
                          [19] Currently, I'm building [22] agents [20] to automate web interaction workflows, leveraging advances in vision-language &
                          code-generation. My undergrad thesis explored semantics in [23] multimodal [21] transformers.
                          [24] Previously, I fine-tuned language models at [26] Microsoft AI [25] and advised startups deploying NLP for various B2B verticals. In
                          my free time, I enjoy reading Sanskrit literature & learning weird math.


                                                                           **[27] Awarded or Cited by**















                          **[46] Experience**
                             **[47] Reworkd (YC S23)**
                             [48] As Founding Research Engineer, I develop [50] AI agents [49] that
                             automate business workflows.



                                                                                         **[53] Ousia**
                                                                                         [54] SEO content writers have to deeply research their topic to know
                                                                                         what to write about. Ousia [55] automates research.
                                                                                         [56] As [58] technical co-founder [57], I built NLP & LLM solutions to
                                                                                         10x our users' article writing ability. Exited via co-founder buyout.

                             **[59] Carnegie Mellon University**                                 **MultiComp**
                             [61] Vision-Language Models [60] drastically fail to represent & align
                             compositional structure (e.g. mug in grass" vs grass in mug" ).
                             [62] In my Honors Thesis, we explore various vectorial approaches
                             inspired by [64] linguistic theory [63] to address this problem, with
                             papers at NeurIPS, EACL, ACL, EMNLP, and ICCV.




                                                                   **[67] Microsoft AI**
                                                                   [68] The AI Platform group at Microsoft builds infrastructure for [70] enterprise-scale
                                                                   [69] machine learning lifecycles on Azure.
                                                                   [71] I fine-tuned [73] distilled LLMs [72] to aid annotators in natural language data
                                                                   labeling, saving compute & improving speed.

                             **[74] Carnegie Mellon University**                                 **NeuLab**
                             [75] Are [77] large language models [76] just learning co-occurence
                             statistics, or can they capture compositional relations as encoded by
                             [78] semantic formalisms
                             [79] We applied graph algorithms to Abstract Meaning Representation
                             to create a task that probes compositional ability. I presented our work
                             at the 2021 SCS Research Fair.


                                                                                                  **[82] Vizerto**
                                                                                                  [83] Vizerto is a [85] digital sales assistant [84] that makes
                                                                                                  domain-specific knowledge easily available to B2B sellers.
                                                                                                  [86] I advised their ML team on novel approaches to [88]
                                                                                                  information retrieval [87], graphical knowledge representations,
                                                                                                  and more.

                             **[89] Language & Dialogue Systems Lab**
                             [90] Our conversational socialbot interacted with thousands of
                             [92] Amazon Alexa [91] users every day, maintaining the top
                             average user rating for 2 months straight against teams from
                             Stanford, USC, and more.
                             [93] My work on user modeling and entity graphs was included in
                             our paper at [94] EMNLP 2021.

                                                                                 **[97] SapientX**
                                                                                 [98] SapientX builds white label intelligent [100] voice assistants [99] for cars,
                                                                                 phones, fridges, and stores.
                                                                                 [101] I fine-tuned state-of-the-art models for [103] extractive question
                                                                                 answering [102] to give Tele the ability to answer domain-specific user queries
                                                                                 from large, unorganized [104] document corpora.

                             **[105] Language, Logic, & Cognition Lab**
                             [106] Can deep reinforcement learning model how humans learn
                             to parse [108] syntax trees [107] from experience?
                             [109] We built a family of cognitively realistic parsing
                             environments to explore how novel neural architectures & RL
                             algorithms could inform psycholinguistic theory. Our work was
                             accepted at [111] NeurIPS 2021 [110] Deep RL workshop.

                                                                                 **[114] Wordcab**
                                                                                 [115] Wordcab summarizes business meetings using the latest in abstractive
                                                                                 [117] neural summarization [116] tech.
                                                                                 [118] I worked with Aleks (CEO) to build topic-based summarization, a
                                                                                 highly-demanded but [120] technologically challenging [119] feature.

                             **[121] Intheon**
                             [122] Intheon builds neural [124] data processing infrastructure [123] used by labs
                             across the world to simplify their brainwave analysis pipelines.
                             [125] I undertook NSF-funded research to investigate how language models could
                             aid [127] brain-computer interfaces [126] in assisting users.

                                                                        **[130] Applied Machine Learning Lab**
                                                                        [131] The AMLL lab applies novel ML research to [133] social good [132] issues
                                                                        primarily in psychology and neuroscience.
                                                                        [134] Our work used hierarchical [136] document representations [135] to identify
                                                                        mental illness in social media discussions and quantify COVID's diachronic effects.

                             **[137] Bunch Inc**
                             [138] Bunch builds enterprise-grade video & [140] computer
                             vision [139] software while exploring related high risk-reward
                             projects.
                             [141] I deployed [143] tensorflow.js [142] pose detection models
                             client-side for a project virtualizing expensive gym equipment.


                          **[145] Publications**
                            [146] Towards Vision-Language Mechanistic Interpretability: a Causal Tracing Tool for BLIP
                            [147] ICCV 2023 Vision-Language Workshop
                            [148] Vedant Palit*, [150] Rohan Pandey* [149], Aryaman Arora, Paul Pu Liang
                            [151] WinogroundVQA: Zero-shot Reasoning with LLMs for Compositional Visual Question Answering
                            [152] Under Review at EMNLP 2023
                            [154] Rohan Pandey [153], Spandan Das, Tristan Thrush, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency
                            [155] Multimodal Learning Without Multimodal Data: Guarantees and Applications
                            [156] Under Review at NeurIPS 2023
                            [157] Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alexander Obolenskiy, Yudong Liu, [159] Rohan Pandey [158], Alex Wilf, Louis-Philippe Morency,
                            Ruslan Salakhutdinov
                            [160] Cross-modal Attention Congruence Regularization for Vision-Language Relation Alignment
                            [@161] ACL 2023
                            [163] Rohan Pandey [162], Rulin Shao, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency
                            [164] Syntax-guided Neural Module Distillation to Probe Compositionality in Sentence Embeddings
                            [@165] EACL 2023
                            [166] Rohan Pandey
                            [167] Does Structural Attention Improve Compositional Representations in Vision-Language Models?
                            [@168] NeurIPS 2022 Self-Supervised Learning Workshop
                            [170] Rohan Pandey [169], Rulin Shao, Paul Pu Liang, Louis-Philippe Morency
                            [171] Probing Compositional Representations in Neural Language Models with Semantic Graphs
                            [172] Preprint, 2022
                            [174] Rohan Pandey [173], Uri Alon, Frank Xu, Graham Neubig
                            [175] A Family of Cognitively Realistic Parsing Environments for Deep Reinforcement Learning
                            [@176] Architectures and Mechanisms for Language Processing 2022
                            [@177] NeurIPS 2021 Deep Reinforcement Learning Workshop
                            [178] Adrian Brasoveanu, [180] Rohan Pandey [179], Maximilian Alfano-Smith
                            [181] Athena 2.0: Contextualized Dialogue Management for an Alexa Prize SocialBot
                            [@182] EMNLP 2021 System Demonstrations
                            [@183] Proceedings of Amazon Alexa Prize Socialbot Grand Challenge 4
                            [184] Juraj Juraska, Kevin K. Bowden, Lena Reed, Vrindavan Harrison, Wen Cui, Omkar Patil, Rishi Rajasekaran, Angela Ramirez, Cecilia Li, Eduardo
                            Zamora, Phillip Lee, Jeshwanth Bheemanpally, [186] Rohan Pandey [185], Adwait Ratnaparkhi, Marilyn Walker
                            [187] Transfer Learning for Mental Health Evaluation from Natural Language
                            [188] Preprint, 2020
                            [189] Kamil Kisielewicz, [191] Rohan Pandey [190], Shivansh Rustagi, Narges Norouzi

                          **[192] Research**
                          [193] I'm interested in questions like...
                          [194] How do humans perform [197] semantic composition [195] and how can we build systems that analyze language compositionally
                          [196]    Transformers have outpaced virtually all other architectures in NLP is something about the self-attention mechanism inherently
                          effective at expressing semantic composition?
                          [203] How do humans [207] ground language [204] in their environment and how can we build systems that understand language in
                          relation to the real world [205]      The dominant approach of learning from large text corpora has gone a long way, but it falls into a trap
                          [206] that can only be avoided by grounding language. How do perception & action modalities influence semantic representations?
                          [215] What is the underlying relationship between [218] symbolic and statistical approaches [216]                          Why do some parts of nature seem
                          so perfectly described [217] by symbolic relations while others don't? Is reality fundamentally symbolic or are symbols a formalism that
                          humans apply to our environment?
                          [221] And a few miscellaneous ones: What makes specifically human brains so good at manipulating symbols, genetically, structurally,
                          and culturally? How does the brain represent non-linguistic thoughts and is all perception symbolic at some level [222]                          How can
                          classical theories from linguistics and philosophy of language [223] aid modern research in NLP? Is internality an inherent property of
                          matter

                          **[227] Projects**








                                                                                [233] Celery                            [238] veda.dev
                                      [229] fbIRL                       [234] Won 2nd & FinTech                [239] Deployed with active users
                             [230] Won 1st      Facebook SF               [235] UCLA Hacks 2019                                                                    [242] sWEep
                                                                                                                [240] Morphology visualizer for
                                  Dev Hackathon 2019                                                                                                        [243] Won 1st       SRC Code
                                                                       [236] Big data forecasting for             Sanskrit literature research &
                               [231] Tomorrow's AR social                  sustainable businesses                           education                                    2018
                                   network (Pre-Meta)                                                                                                     [244] Cleaning neighborhoods
                                                                                                                                                                with computer vision




                                                                             [250] We & You
                                                                        [251] Won Google Cloud                             [254] Phil
                                 [246] Latent Space                           BASEHacks 2018                   [255] Won Amazon & Blockchain
                            [247] Won 3rd       HackMIT 2020                                                              CruzHacks 2019                        [258] Boolepathy
                                                                     [252] Peer-to-peer mental health                                                          [259] Won 1st in US
                              [248] Domain-specific neural                    services for teens                  [256] Facilitating blockchain               [260] NeuroTechX 2020
                              audio compression for virtual                                                       donations with Alexa skill art
                                          bands                                                                                                             [261] Non-invasive synthetic
                                                                                                                                                                       telepathy


                          **[262] Fun Facts**
                            [263] I'm a philosophy enthusiast and tend to align with the M m s school [264] of Indian thought.
                            [266] I still have much to learn in higher math, but I'm intrigued by topological models [267] of natural language semantics.
                            [272] I've been teaching myself Sanskrit [273] and Mandarin Chinese since 2018. I'm fluent in English, Hindi, and Spanish, as well as a
                            [mediocre] Tamil heritage speaker. I've dabbled in French, Arabic, Japanese, Hebrew, Russian, and Greek.
                            [275] I enjoy building constructed languages [276], including a 2-channel parallelized experimental lang and a modern descendant of
                            Sumerian.
                            [278] I founded NeuroTechSC [279], which I led to winning 1st in the US at NeuroTechX's 2020 student competition with our 25 student
                            team and subvocal recognition BCI [280]. I was also Vice President of UCSC's AI club, SCAI.
                            [284] My current reading list includes G del, Escher, Bach (Hofstadter), Every Life is on Fire (England), and Arthasa graha (Bh
                            skara).
                            [285] The source code for this site is based on Andrej Karpathy's personal website.
                            [287] Feel free to reach out to chat!
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Token count: 2973